{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d2ad7a",
   "metadata": {},
   "source": [
    "# Deliverable 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2fbece",
   "metadata": {},
   "source": [
    "SNumbers: u264332, u264443, u264202\n",
    "\n",
    "Names: Levente Olivér Bódi, Riccardo Zamuner, Giada Izzo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3b603",
   "metadata": {},
   "source": [
    "## Previous deliverable code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd734c6",
   "metadata": {},
   "source": [
    "This is the same code of the previous deliverable minus prints and commentary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d228d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/just_riccio/sage/sage/venv/lib/python3.12/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/just_riccio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/just_riccio/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b9f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess a text by tokenizing, lowercasing, removing stop words, and stemming.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Remove punctuation\n",
    "    tokens = [re.sub(r\"[^\\w\\s]\", \"\", token) for token in tokens]\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Remove punctuation\n",
    "    tokens = [re.sub(r\"[^\\w\\s]\", \"\", token) for token in tokens]\n",
    "\n",
    "    # Stem the tokens\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    # Remove empty strings\n",
    "    tokens = [token for token in tokens if token]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def clean_seller(text):\n",
    "    \"\"\"\n",
    "    Clean the seller field by removing unwanted trailing phrases.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove unwanted trailing phrases and everything after them\n",
    "    remove_phrases = [\n",
    "        \"Seller changed\",\n",
    "        \"(Not Enough Ratin\",\n",
    "        \"(New Sell\"\n",
    "    ]\n",
    "    for phrase in remove_phrases:\n",
    "        idx = text.find(phrase)\n",
    "        if idx != -1:\n",
    "            text = text[:idx]\n",
    "    return text.strip()\n",
    "\n",
    "def preprocess_non_textual(document):\n",
    "    \"\"\"\n",
    "    Preprocess non-textual fields in the document.\n",
    "    \"\"\"\n",
    "\n",
    "    # Discount preprocessing: convert from string \"xx% off\" to integer xx\n",
    "    # also taking into account documents without discount\n",
    "    if isinstance(document[\"discount\"], str) and \"%\" in document[\"discount\"]:\n",
    "        document[\"discount\"] = int(document[\"discount\"][:document[\"discount\"].find(\"%\")])\n",
    "    else:\n",
    "        document[\"discount\"] = 0\n",
    "        \n",
    "    # Merge all values from product_details dictionary and preprocess\n",
    "    if isinstance(document[\"product_details\"], dict):\n",
    "        details_text = \" \".join(str(v) for v in document[\"product_details\"].values())\n",
    "    elif isinstance(document[\"product_details\"], list):\n",
    "        # If it's a list of dicts, merge all values from all dicts\n",
    "        details_text = \" \".join(str(v) for d in document[\"product_details\"] if isinstance(d, dict) for v in d.values())\n",
    "    else:\n",
    "        details_text = str(document[\"product_details\"])\n",
    "    document[\"product_details\"] = preprocess_text(details_text)\n",
    "\n",
    "    # Convert actual_price and selling_price to integers (remove commas)\n",
    "    # If actual_price is NaN, set it to discounted selling_price\n",
    "    for price_field in [\"actual_price\", \"selling_price\"]:\n",
    "        if isinstance(document[price_field], str):\n",
    "            price_str = document[price_field].replace(\",\", \"\")\n",
    "            price_val = price_str.split(\".\")[0]\n",
    "            document[price_field] = int(price_val) if price_val.isdigit() else 0\n",
    "\n",
    "    # If actual_price is missing or zero, set it to discounted selling_price\n",
    "    if (\"actual_price\" not in document or document[\"actual_price\"] == 0) and \"selling_price\" in document:\n",
    "        document[\"actual_price\"] = int(int(document[\"selling_price\"])*document[\"discount\"]/100)\n",
    "\n",
    "    # Convert average_rating to float, set to NaN if missing or empty\n",
    "    if \"average_rating\" in document and str(document[\"average_rating\"]).strip() != \"\":\n",
    "        try:\n",
    "            document[\"average_rating\"] = float(document[\"average_rating\"])\n",
    "        except ValueError:\n",
    "            document[\"average_rating\"] = float(\"nan\")\n",
    "    else:\n",
    "        document[\"average_rating\"] = float(\"nan\")\n",
    "\n",
    "    return document\n",
    "\n",
    "def preprocess_document(document):\n",
    "    \"\"\"\n",
    "    Join all preprocessing steps for a document.\n",
    "    \"\"\"\n",
    "\n",
    "    document[\"description\"] = preprocess_text(document[\"description\"])\n",
    "    document[\"title\"] = preprocess_text(document[\"title\"])\n",
    "    document[\"seller\"] = clean_seller(document[\"seller\"])\n",
    "    document[\"brand\"] = document[\"brand\"].lower().split()\n",
    "\n",
    "    document = preprocess_non_textual(document)\n",
    "\n",
    "    return document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977d4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY THIS PATH AS NEEDED\n",
    "file_path = \"../../data/fashion_products_dataset.json\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0e1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_actual_price(row):\n",
    "    # if actual_price is empty, try to compute it:\n",
    "    # either from selling_price and discount, or just use selling_price\n",
    "    if row['actual_price'] == '':\n",
    "        # Convert selling_price and discount to float if not empty\n",
    "        if row['selling_price'] != '' and row['discount'] != '':\n",
    "            selling_price = float(str(row['selling_price']).replace(',', ''))\n",
    "            discount = float(str(row['discount']).replace('%', '').replace('off', '').strip())\n",
    "            return selling_price * (1 - discount / 100)\n",
    "        elif row['selling_price'] != '':\n",
    "            return float(str(row['selling_price']).replace(',', ''))\n",
    "    return row['actual_price']\n",
    "\n",
    "df['discount'] = df['discount'].replace('', '0')\n",
    "df['actual_price'] = df.apply(impute_actual_price, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50f0e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the remaining products without price\n",
    "df = df[(df['actual_price'] != '') & (df['selling_price'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad072e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty brand names with 'no brand'\n",
    "df.loc[df['brand'] == '', 'brand'] = 'no brand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5f0361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(preprocess_document, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f4169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def normalize_cat_token(val):\n",
    "    if pd.isna(val) or str(val).strip() == \"\":\n",
    "        return []\n",
    "    # split common multi-value strings; keep a single value as 1-item list\n",
    "    parts = re.split(r\"[\\/,;|]\", str(val))\n",
    "    return [re.sub(r\"\\s+\", \"_\", p.strip().lower()) for p in parts if p.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90d15d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inverted_index_df(df: pd.DataFrame,id_col: str | None = None,text_cols: list[str] = (\"title\", \"description\", \"product_details\"),min_df: int = 1,store_positions: bool = False):\n",
    "    \"\"\"\n",
    "    df: preprocessed dataframe (title/description/product_details are token lists).\n",
    "    id_col: column holding unique ids; if None, uses df.index (as str).\n",
    "    text_cols: columns with *token lists* (already stemmed, stopwords removed).\n",
    "    min_df: drop terms that appear in < min_df documents.\n",
    "    store_positions: if True, also keep term positions for phrase/proximity queries.\n",
    "    \"\"\"\n",
    "    # assign doc ID's\n",
    "    doc_ids = df[id_col].astype(str).tolist() if id_col else df.index.astype(str).tolist()\n",
    "\n",
    "    per_doc_terms = []\n",
    "    per_doc_sequence = []\n",
    "\n",
    "    # gather tokens for each row\n",
    "    for _, row in df.iterrows():\n",
    "        tokens = []\n",
    "\n",
    "        # text cols are already tokenized lists after preprocess_document(), we just make it robust if something slipped through\n",
    "        for c in text_cols:\n",
    "            if c in df.columns:\n",
    "                vals = row[c]\n",
    "                if isinstance(vals, (list, tuple)):\n",
    "                    tokens.extend([str(t).lower() for t in vals if str(t).strip()])\n",
    "                elif pd.notna(vals):\n",
    "                    # if something slipped through as string, tokenize lightly:\n",
    "                    tokens.extend(re.findall(r\"[A-Za-z0-9]+\", str(vals).lower()))\n",
    "\n",
    "\n",
    "        # ensure we have a sequence for positions and a set for boolean presence\n",
    "        if store_positions:\n",
    "            per_doc_sequence.append(tokens[:])\n",
    "        per_doc_terms.append(set(tokens))\n",
    "\n",
    "    # build postings (term -> list[doc_id]) and df counts\n",
    "    postings_tmp = defaultdict(list)\n",
    "    df_count = defaultdict(int)\n",
    "\n",
    "    for d_i, terms in enumerate(per_doc_terms):\n",
    "        did = doc_ids[d_i]\n",
    "        for term in terms:\n",
    "            postings_tmp[term].append(did)\n",
    "            df_count[term] += 1\n",
    "\n",
    "    # min_df filter + sort postings\n",
    "    postings_tmp = {t: sorted(dids) for t, dids in postings_tmp.items() if df_count[t] >= min_df}\n",
    "\n",
    "    # vocab\n",
    "    vocab = {term: tid for tid, term in enumerate(sorted(postings_tmp.keys()))}\n",
    "    id2term = {tid: term for term, tid in vocab.items()}\n",
    "\n",
    "    # final inverted index (term_id -> [doc_ids])\n",
    "    inv_index = {vocab[t]: dids for t, dids in postings_tmp.items()}\n",
    "\n",
    "    # positional index\n",
    "    positional = None\n",
    "    if store_positions:\n",
    "        positional = {tid: defaultdict(list) for tid in inv_index.keys()}\n",
    "        for d_i, seq in enumerate(per_doc_sequence):\n",
    "            did = doc_ids[d_i]\n",
    "            for pos, tok in enumerate(seq):\n",
    "                if tok in vocab:\n",
    "                    tid = vocab[tok]\n",
    "                    positional[tid][did].append(pos)\n",
    "        # convert inner dicts to normal dicts\n",
    "        positional = {tid: dict(dmap) for tid, dmap in positional.items()}\n",
    "\n",
    "    return {\n",
    "        \"vocab\": vocab,            # term -> term_id\n",
    "        \"id2term\": id2term,        # term_id -> term\n",
    "        \"postings\": inv_index,     # term_id -> [doc_id, ...] (sorted)\n",
    "        \"doc_ids\": doc_ids,        # all doc ids, as strings\n",
    "        \"positional\": positional   # optional: term_id -> {doc_id: [positions]}\n",
    "    }\n",
    "\n",
    "index_obj = build_inverted_index_df(\n",
    "    df,\n",
    "    id_col=None,\n",
    "    text_cols=df.columns,\n",
    "    min_df=1,\n",
    "    store_positions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd7f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick lookups\n",
    "def docs_for_term(term: str):\n",
    "    \"\"\"Return document IDs for a raw term or categorical token (e.g., 'brand:nike').\"\"\"\n",
    "    tid = index_obj[\"vocab\"].get(term)\n",
    "    return index_obj[\"postings\"].get(tid, []) if tid is not None else []\n",
    "\n",
    "def doc_positions_for_term(term: str, doc_id: str):\n",
    "    \"\"\"Return positions of term in a specific document.\"\"\"\n",
    "    tid = index_obj[\"vocab\"].get(term)\n",
    "    if tid is None:\n",
    "        return []\n",
    "    return index_obj[\"positional\"].get(tid, {}).get(doc_id, [])\n",
    "\n",
    "def and_query(terms: list[str]):\n",
    "    \"\"\"Boolean AND over terms.\"\"\"\n",
    "    sets = [set(docs_for_term(t)) for t in terms]\n",
    "    return sorted(set.intersection(*sets)) if sets else []\n",
    "\n",
    "def or_query(terms: list[str]):\n",
    "    \"\"\"Boolean OR over terms.\"\"\"\n",
    "    s = set()\n",
    "    for t in terms:\n",
    "        s.update(docs_for_term(t))\n",
    "    return sorted(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b31c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = {\n",
    "    \"Q1\": \"cotton tshirt 50 100 men blue\",\n",
    "    \"Q2\": \"adidas red\",\n",
    "    \"Q3\": \"denim jean skinny\",\n",
    "    \"Q4\": \"dress red\",\n",
    "    \"Q5\": \"leather jacket\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb0d2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf(word, document):\n",
    "    \"\"\"\n",
    "    Calculate term frequency for a word in a document.\n",
    "    TF = Number of times term t appears in a document\n",
    "    \"\"\"\n",
    "    return document.count(word)    \n",
    "    \n",
    "\n",
    "def calculate_idf(word, all_documents):\n",
    "    \"\"\"\n",
    "    Calculate inverse document frequency for a word.\n",
    "    IDF = log(Total number of documents / Number of documents containing term t)\n",
    "    \"\"\"\n",
    "    num_documents_with_term = len(docs_for_term(word))\n",
    "    if num_documents_with_term == 0:\n",
    "        return 0\n",
    "    return np.log(len(all_documents) / num_documents_with_term)\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62a2ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_documents(query, documents, k):\n",
    "    \"\"\"\n",
    "    Rank documents based on TF-IDF scores for the given query.\n",
    "    Return the top k documents.\n",
    "    \"\"\"\n",
    "    all_documents = [doc[\"description\"] + doc[\"title\"] + doc[\"brand\"] for index, doc in documents.iterrows()]\n",
    "    scores = []\n",
    "\n",
    "    term_idfs = {term: calculate_idf(term, all_documents) for term in query}\n",
    "    query_vector = np.array([calculate_tf(term, query) * term_idfs[term] for term in query])\n",
    "\n",
    "    for index, doc in documents.iterrows():\n",
    "        doc_vec = []\n",
    "        doc_text = doc[\"description\"] + doc[\"title\"] + doc[\"brand\"]\n",
    "        for term in query:\n",
    "            tf = calculate_tf(term, doc_text)\n",
    "            if tf > 0:\n",
    "                # used the formula tf = 1 + log_10(count)\n",
    "                doc_vec.append((1 + np.log(tf)) * term_idfs[term])\n",
    "            else:\n",
    "                doc_vec.append(0)\n",
    "        scores.append((doc, cosine_similarity(query_vector, np.array(doc_vec))))\n",
    "\n",
    "    # Sort documents by score in descending order\n",
    "    ranked_docs = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return ranked_docs[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08af6677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(retrieved_docs, relevant_docs, k):\n",
    "    \"\"\"\n",
    "    Calculate Precision@k.\n",
    "    Precision@k = (Number of relevant documents retrieved in top k) / k\n",
    "    \"\"\"\n",
    "    retrieved_at_k = retrieved_docs[:k]\n",
    "    relevant_retrieved = sum(1 for doc in retrieved_at_k if doc[\"pid\"] in relevant_docs)\n",
    "    return relevant_retrieved / k if k > 0 else 0\n",
    "\n",
    "def recall_at_k(retrieved_docs, relevant_docs, k):\n",
    "    \"\"\"\n",
    "    Calculate Recall@k.\n",
    "    Recall@k = (Number of relevant documents retrieved in top k) / (Total number of relevant documents)\n",
    "    \"\"\"\n",
    "    retrieved_at_k = retrieved_docs[:k]\n",
    "    relevant_retrieved = sum(1 for doc in retrieved_at_k if doc[\"pid\"] in relevant_docs)\n",
    "    total_relevant = len(relevant_docs)\n",
    "    return relevant_retrieved / total_relevant if total_relevant > 0 else 0\n",
    "\n",
    "def average_precision_at_k(retrieved_docs, relevant_docs, k):\n",
    "    \"\"\"\n",
    "    Calculate Average Precision@k.\n",
    "    AP@k = Average of Precision@i for each relevant document retrieved in top k\n",
    "    \"\"\"\n",
    "    retrieved_at_k = retrieved_docs[:k]\n",
    "    relevant_retrieved = 0\n",
    "    precision_sum = 0\n",
    "\n",
    "    for i, doc in enumerate(retrieved_at_k, start=1):\n",
    "        if doc[\"pid\"] in relevant_docs:\n",
    "            relevant_retrieved += 1\n",
    "            precision_sum += relevant_retrieved / i\n",
    "\n",
    "    return precision_sum / relevant_retrieved if relevant_retrieved > 0 else 0\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    \"\"\"\n",
    "    Calculate F1 Score.\n",
    "    F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    \"\"\"\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def f1_score_at_k(retrieved_docs, relevant_docs, k):\n",
    "    \"\"\"\n",
    "    Calculate F1 Score at k.\n",
    "    \"\"\"\n",
    "    precision = precision_at_k(retrieved_docs, relevant_docs, k)\n",
    "    recall = recall_at_k(retrieved_docs, relevant_docs, k)\n",
    "    return f1_score(precision, recall)\n",
    "\n",
    "def mean_average_precision(retrieved_docs_list, relevant_docs_list, k):\n",
    "    \"\"\"\n",
    "    Calculate Mean Average Precision (MAP) at k.\n",
    "    MAP = Mean of Average Precision@k over all queries\n",
    "    \"\"\"\n",
    "    ap_sum = 0\n",
    "    num_queries = len(retrieved_docs_list)\n",
    "\n",
    "    for retrieved_docs, relevant_docs in zip(retrieved_docs_list, relevant_docs_list):\n",
    "        ap_sum += average_precision_at_k(retrieved_docs, relevant_docs, k)\n",
    "\n",
    "    return ap_sum / num_queries if num_queries > 0 else 0\n",
    "\n",
    "def reciprocal_rank(retrieved_docs, relevant_docs):\n",
    "    \"\"\"\n",
    "    Calculate Reciprocal Rank (RR).\n",
    "    RR = 1 / Rank of the first relevant document\n",
    "    \"\"\"\n",
    "    rank = 0\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        if doc[\"pid\"] in relevant_docs:\n",
    "            rank = i + 1\n",
    "            break\n",
    "    return 1 / rank if rank > 0 else 0\n",
    "\n",
    "def mean_reciprocal_rank(retrieved_docs_list, relevant_docs_list):\n",
    "    \"\"\"\n",
    "    Calculate Mean Reciprocal Rank (MRR).\n",
    "    MRR = Mean of Reciprocal Ranks over all queries\n",
    "    \"\"\"\n",
    "    rr_sum = 0\n",
    "    num_queries = len(retrieved_docs_list)\n",
    "\n",
    "    for retrieved_docs, relevant_docs in zip(retrieved_docs_list, relevant_docs_list):\n",
    "        rr_sum += reciprocal_rank(retrieved_docs, relevant_docs)\n",
    "\n",
    "    return rr_sum / num_queries if num_queries > 0 else 0\n",
    "\n",
    "def dcg_at_k(retrieved_docs, relevant_docs, k):\n",
    "    \"\"\"\n",
    "    Calculate Discounted Cumulative Gain (DCG) at k.\n",
    "    DCG@k = Sum of (relevance of document at rank i) / log2(i + 1) for i in 1 to k\n",
    "    \"\"\"\n",
    "    dcg = 0\n",
    "    for i in range(min(k, len(retrieved_docs))):\n",
    "        doc = retrieved_docs[i]\n",
    "        if doc[\"pid\"] in relevant_docs:\n",
    "            relevance = 1  # we only have binary relevance\n",
    "        else:\n",
    "            relevance = 0\n",
    "        dcg += relevance / np.log2(i + 2)  # i + 2 because i starts from 0\n",
    "    return dcg\n",
    "\n",
    "def ndcg_at_k(retrieved_docs, relevant_docs, k):\n",
    "    \"\"\"\n",
    "    Calculate Normalized Discounted Cumulative Gain (NDCG) at k.\n",
    "    NDCG@k = DCG@k / IDCG@k\n",
    "    \"\"\"\n",
    "    dcg = dcg_at_k(retrieved_docs, relevant_docs, k)\n",
    "    \n",
    "    ideal_retrieved_docs = [{\"pid\": pid} for pid in relevant_docs]\n",
    "    idcg = dcg_at_k(ideal_retrieved_docs, relevant_docs, k)\n",
    "    \n",
    "    return dcg / idcg if idcg > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3_part3_title",
   "metadata": {},
   "source": [
    "## Ranking & Filtering\n",
    "\n",
    "In this part, we implement a retrieval pipeline that:\n",
    "- Takes a text query as input.\n",
    "- Finds all documents that contain all query terms (AND semantics).\n",
    "- Sorts the matching documents by relevance using multiple ranking methods:\n",
    "  1. TF‑IDF + cosine similarity\n",
    "  2. BM25\n",
    "  3. Our custom score (text relevance + numeric feature boosts)\n",
    "\n",
    "We also implement a Word2Vec + cosine ranking and return top 20 lists for the 5 queries defined in Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3_prep_globals_md",
   "metadata": {},
   "source": [
    "### Global text corpus statistics for ranking\n",
    "We precompute text tokens per document (description + title + brand), document lengths, and per term document frequencies over these fields, which we will reuse for TF‑IDF and BM25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3_prep_globals",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a text-only view per document (description + title + brand)\n",
    "ALL_TEXT_DOCS = [row[\"description\"] + row[\"title\"] + row[\"brand\"] for _, row in df.iterrows()]\n",
    "N_TEXT = len(ALL_TEXT_DOCS)\n",
    "\n",
    "# Document lengths and average length\n",
    "DOC_LENGTHS = np.array([len(toks) for toks in ALL_TEXT_DOCS], dtype=float)\n",
    "AVG_DL = float(DOC_LENGTHS.mean()) if N_TEXT > 0 else 0.0\n",
    "\n",
    "# Document frequency per term over the text only view\n",
    "from collections import Counter\n",
    "DF_TEXT = Counter()\n",
    "for toks in ALL_TEXT_DOCS:\n",
    "    DF_TEXT.update(set(toks))\n",
    "\n",
    "def idf_text(term: str) -> float:\n",
    "    \"\"\"IDF using text only df: log(N / df)\"\"\"\n",
    "    df_t = DF_TEXT.get(term, 0)\n",
    "    if df_t == 0 or N_TEXT == 0:\n",
    "        return 0.0\n",
    "    return np.log(N_TEXT / df_t)\n",
    "\n",
    "def idf_bm25(term: str) -> float:\n",
    "    \"\"\"BM25 IDF: log((N - df + 0.5) / (df + 0.5) + 1)\"\"\"\n",
    "    df_t = DF_TEXT.get(term, 0)\n",
    "    return np.log(((N_TEXT - df_t + 0.5) / (df_t + 0.5)) + 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3_pipeline_md",
   "metadata": {},
   "source": [
    "### AND-conjunctive retrieval pipeline\n",
    "We standardize query preprocessing to match the document pipeline and use the inverted index to fetch conjunctive candidates before ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3_pipeline_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(q):\n",
    "    \"\"\"Accepts a string or list of strings; returns normalized tokens using the same preprocessing as documents\"\"\"\n",
    "    if isinstance(q, str):\n",
    "        return preprocess_text(q)\n",
    "    elif isinstance(q, (list, tuple)):\n",
    "        return preprocess_text(\" \".join(map(str, q)))\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def retrieve_conjunctive_candidates(query_tokens):\n",
    "    \"\"\"Return candidate doc indices (list of ints) where all query terms appear (AND)\"\"\"\n",
    "    if not query_tokens:\n",
    "        return []\n",
    "    dids = and_query(query_tokens)\n",
    "    return [int(d) for d in dids]\n",
    "\n",
    "def doc_text_tokens(row):\n",
    "    return row[\"description\"] + row[\"title\"] + row[\"brand\"]\n",
    "\n",
    "def cosine(v1, v2):\n",
    "    return cosine_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3_rankers_md",
   "metadata": {},
   "source": [
    "### Ranking methods\n",
    "We provide three ranking functions over the conjunctive candidates:\n",
    "- TF‑IDF + cosine similarity\n",
    "- BM25\n",
    "- Custom hybrid score (text relevance + numeric boosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3_rankers_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_tfidf_cosine(query_tokens, candidate_indices, k=10):\n",
    "    # Unique terms to define vector space\n",
    "    terms = list(dict.fromkeys(query_tokens))\n",
    "    # Query vector (tf-idf)\n",
    "    q_vec = np.array([(1 + np.log(query_tokens.count(t))) * idf_text(t) if query_tokens.count(t) > 0 else 0.0 for t in terms])\n",
    "\n",
    "    scored = []\n",
    "    for idx in candidate_indices:\n",
    "        row = df.iloc[idx]\n",
    "        toks = doc_text_tokens(row)\n",
    "        d_vec = []\n",
    "        for t in terms:\n",
    "            tf = toks.count(t)\n",
    "            d_vec.append(((1 + np.log(tf)) * idf_text(t)) if tf > 0 else 0.0)\n",
    "        d_vec = np.array(d_vec)\n",
    "        score = cosine(q_vec, d_vec)\n",
    "        scored.append((row, score))\n",
    "    return sorted(scored, key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "def rank_bm25(query_tokens, candidate_indices, k=10, k1=1.5, b=0.75):\n",
    "    scored = []\n",
    "    for idx in candidate_indices:\n",
    "        row = df.iloc[idx]\n",
    "        toks = doc_text_tokens(row)\n",
    "        dl = len(toks)\n",
    "        score = 0.0\n",
    "        for t in set(query_tokens):\n",
    "            tf = toks.count(t)\n",
    "            if tf == 0:\n",
    "                continue\n",
    "            idf = idf_bm25(t)\n",
    "            denom = tf + k1 * (1 - b + b * (dl / (AVG_DL if AVG_DL > 0 else 1.0)))\n",
    "            score += idf * (tf * (k1 + 1)) / denom\n",
    "        scored.append((row, score))\n",
    "    return sorted(scored, key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "# Global numeric ranges for normalization\n",
    "SELL_MIN, SELL_MAX = float(pd.to_numeric(df['selling_price'], errors='coerce').min()), float(pd.to_numeric(df['selling_price'], errors='coerce').max())\n",
    "DISC_MIN, DISC_MAX = float(pd.to_numeric(df['discount'], errors='coerce').min()), float(pd.to_numeric(df['discount'], errors='coerce').max())\n",
    "RAT_MIN, RAT_MAX = 0.0, 5.0  # ratings are on 0..5 scale\n",
    "\n",
    "def _norm(x, lo, hi):\n",
    "    try:\n",
    "        xv = float(x)\n",
    "    except Exception:\n",
    "        xv = 0.0\n",
    "    if hi <= lo:\n",
    "        return 0.0\n",
    "    return (xv - lo) / (hi - lo)\n",
    "\n",
    "def rank_custom_hybrid(query_tokens, candidate_indices, k=10,\n",
    "                       base='bm25', k1=1.5, b=0.75,\n",
    "                       w_rating=0.30, w_discount=0.20, w_price=0.10):\n",
    "    \"\"\"\n",
    "    Custom score = BaseTextScore * (1 + w_rating*rating_norm + w_discount*discount_norm - w_price*price_norm)\n",
    "    - BaseTextScore: BM25 (default) or TF‑IDF cosine\n",
    "    - Boosts: higher rating and discount help; higher price penalizes slightly\n",
    "    \"\"\"\n",
    "    # Precompute base scores once\n",
    "    if base == 'bm25':\n",
    "        base_scored = rank_bm25(query_tokens, candidate_indices, k=len(candidate_indices), k1=k1, b=b)\n",
    "    else:\n",
    "        base_scored = rank_tfidf_cosine(query_tokens, candidate_indices, k=len(candidate_indices))\n",
    "\n",
    "    out = []\n",
    "    for row, base_score in base_scored:\n",
    "        rating = 0.0 if pd.isna(row.get('average_rating', np.nan)) else float(row['average_rating'])\n",
    "        discount = row.get('discount', 0)\n",
    "        price = row.get('selling_price', 0)\n",
    "\n",
    "        rating_n = _norm(rating, RAT_MIN, RAT_MAX)\n",
    "        discount_n = _norm(discount, DISC_MIN, DISC_MAX)\n",
    "        price_n = _norm(price, SELL_MIN, SELL_MAX)\n",
    "\n",
    "        factor = 1.0 + (w_rating * rating_n) + (w_discount * discount_n) - (w_price * price_n)\n",
    "        final_score = float(base_score) * max(factor, 0.0)\n",
    "        out.append((row, final_score))\n",
    "\n",
    "    return sorted(out, key=lambda x: x[1], reverse=True)[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3_rankers_compare_md",
   "metadata": {},
   "source": [
    "### TF‑IDF vs BM25: Pros and Cons\n",
    "\n",
    "- TF‑IDF + cosine\n",
    "  - Pros: simple, fast, well understood; natural cosine normalization makes it robust to document length to some extent.\n",
    "  - Cons: raw tf grows unbounded and favors long documents; no saturation, so additional occurrences keep boosting; length normalization is implicit and weaker than BM25.\n",
    "\n",
    "- BM25\n",
    "  - Pros: tf saturation (diminishing returns); explicit length normalization with parameter b; strong and robust baseline in IR.\n",
    "  - Cons: requires hyperparameters (k1, b); scores are not normalized to [0,1] which can make mixing with other features less straightforward.\n",
    "\n",
    "Our custom hybrid score starts from a strong text base (BM25) and adds interpretable business signals: higher rating and bigger discount are preferred, while very high price is slightly penalized. This can better reflect user utility when text matches are similar. Downsides: requires choosing weights and assumes the same utility for all users (no personalization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3_demo_rank_md",
   "metadata": {},
   "source": [
    "### Conjunctive retrieval + ranking (TF‑IDF, BM25, Custom)\n",
    "We run the 5 queries from Part 2 through the conjunctive filter and show the top‑10 pids for each ranking method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3_demo_rank_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_pid_title(scored, k=10):\n",
    "    out = []\n",
    "    for row, s in scored[:k]:\n",
    "        title_str = \" \".join(row['title']) if isinstance(row['title'], list) else str(row['title'])\n",
    "        out.append((row['pid'], round(float(s), 4), title_str))\n",
    "    return out\n",
    "\n",
    "demo_results = {}\n",
    "for qid, q_terms in test_queries.items():\n",
    "    q_tokens = preprocess_query(q_terms)\n",
    "    cand_idx = retrieve_conjunctive_candidates(q_tokens)\n",
    "    tfidf_res = rank_tfidf_cosine(q_tokens, cand_idx, k=10)\n",
    "    bm25_res = rank_bm25(q_tokens, cand_idx, k=10)\n",
    "    custom_res = rank_custom_hybrid(q_tokens, cand_idx, k=10, base='bm25')\n",
    "    demo_results[qid] = {\n",
    "        'TFIDF': top_k_pid_title(tfidf_res, 10),\n",
    "        'BM25': top_k_pid_title(bm25_res, 10),\n",
    "        'CUSTOM': top_k_pid_title(custom_res, 10)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3_demo_rank_print",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 TFIDF top-10: [('TSHFZKM8HSCZDQER', 0.2952, 'graphic print men round neck black dark blue tshirt pack 2'), ('TSHFZPENQKGHKYTU', 0.2952, 'graphic print men round neck dark blue red tshirt pack 2'), ('TSHFZQ3HHXFYTQJG', 0.2952, 'graphic print men round neck pink dark blue tshirt pack 2'), ('TSHFZQZAZD8MYBGZ', 0.2952, 'graphic print men round neck beig dark blue tshirt pack 2'), ('TSHFZQZAE9C5UTTD', 0.2952, 'graphic print men round neck white dark blue tshirt pack 2'), ('TSHFZ9JSB5MB9AAG', 0.2936, 'solid men v neck dark blue tshirt'), ('TSHFZ9K3AX2MBCPM', 0.2936, 'solid men round neck blue tshirt'), ('TSHFKKC5HS8TEJZW', 0.2936, 'stripe men polo neck blue tshirt'), ('TSHFYPGNHMKRUWAH', 0.2923, 'print men round neck dark blue tshirt'), ('TSHFYWFQMUCGYVUV', 0.2854, 'graphic print women round neck dark blue tshirt')]\n",
      "Q1 BM25 top-10: [('TSHFYPGNHMKRUWAH', 6.3481, 'print men round neck dark blue tshirt'), ('TSHFNWZUHE6PTYUG', 6.1676, 'typographi women round neck blue tshirt'), ('TSHFZ9K3AX2MBCPM', 6.1138, 'solid men round neck blue tshirt'), ('TSHFZ9JSB5MB9AAG', 6.0492, 'solid men v neck dark blue tshirt'), ('TSHFZKM8HSCZDQER', 5.7877, 'graphic print men round neck black dark blue tshirt pack 2'), ('TSHFZPENQKGHKYTU', 5.7877, 'graphic print men round neck dark blue red tshirt pack 2'), ('TSHFZQ3HHXFYTQJG', 5.7877, 'graphic print men round neck pink dark blue tshirt pack 2'), ('TSHFZQZAZD8MYBGZ', 5.7877, 'graphic print men round neck beig dark blue tshirt pack 2'), ('TSHFZQZAE9C5UTTD', 5.7877, 'graphic print men round neck white dark blue tshirt pack 2'), ('TSHFZ6DBE7GBBF2T', 5.6537, 'graphic print women round neck light blue tshirt')]\n",
      "Q1 CUSTOM top-10: [('TSHFYWFQMUCGYVUV', 7.2062, 'graphic print women round neck dark blue tshirt'), ('TSHFYWFQCPZUSTGX', 7.2062, 'graphic print women round neck dark blue tshirt'), ('TSHFYPGNHMKRUWAH', 7.0537, 'print men round neck dark blue tshirt'), ('TSHFNWZUHE6PTYUG', 6.853, 'typographi women round neck blue tshirt'), ('TSHFZ9K3AX2MBCPM', 6.803, 'solid men round neck blue tshirt'), ('TSHFZ9JSB5MB9AAG', 6.7292, 'solid men v neck dark blue tshirt'), ('TSHFH8HGZQYERVKF', 6.705, 'solid men polo neck red white blue tshirt pack 3'), ('TSHFUNN2PHXF7GUH', 6.4464, 'solid men round neck dark blue tshirt'), ('TSHFZKM8HSCZDQER', 6.4237, 'graphic print men round neck black dark blue tshirt pack 2'), ('TSHFZPENQKGHKYTU', 6.4237, 'graphic print men round neck dark blue red tshirt pack 2')]\n",
      "Q2 TFIDF top-10: [('TSHFZF6KF2GKH5ZM', 1.0, 'solid women round neck red tshirt'), ('TSHFZF6KAAJ3QBBZ', 0.9872, 'print women round neck red tshirt')]\n",
      "Q2 BM25 top-10: [('TSHFZF6KAAJ3QBBZ', 12.6267, 'print women round neck red tshirt'), ('TSHFZF6KF2GKH5ZM', 10.2671, 'solid women round neck red tshirt')]\n",
      "Q2 CUSTOM top-10: [('TSHFZF6KAAJ3QBBZ', 16.2653, 'print women round neck red tshirt'), ('TSHFZF6KF2GKH5ZM', 13.6554, 'solid women round neck red tshirt')]\n",
      "Q3 TFIDF top-10: [('TROFEQPUT59QKTKW', 1.0, 'taper women brown cotton linen blend trouser'), ('CRGFENCYZHHAK6PG', 1.0, 'men cargo'), ('TROFEQPUZ3MWMZE3', 1.0, 'taper women brown cotton linen blend trouser'), ('JEAEYNV6QZHJZFRH', 1.0, 'skinni women green jean'), ('JEAEYNV7Y7SGZAJB', 1.0, 'skinni men purpl jean'), ('JEAF6HFHG2FGKHBG', 1.0, 'skinni men green jean'), ('JEAF6HFHPSWA3FTS', 1.0, 'skinni women green jean'), ('JEAFMFFBMZZGCPYK', 0.9796, 'super skinni men black jean'), ('JEAFMFFBVRT3TBQM', 0.9796, 'super skinni women blue jean'), ('JEAFMFFBRXSUPJX5', 0.9796, 'skinni women blue jean')]\n",
      "Q3 BM25 top-10: [('JEAFWBJKAY9UHW8T', 14.3896, 'skinni women blue jean'), ('JEAFUZXSYS6GHGYH', 13.8389, 'skinni women blue jean'), ('JEAFUZXTDFARUHFR', 13.8389, 'skinni men blue jean'), ('JEAFUZXTFZGGMYFB', 13.8389, 'skinni women blue jean'), ('JEAFUZXSBBCAY7V6', 13.8389, 'skinni women grey jean'), ('JEAFUZXTHCYGZJFH', 13.8389, 'skinni men grey jean'), ('JEAFUZXS4AGG5HAQ', 13.8389, 'skinni women blue jean'), ('JEAFUZXTHR9UUXCG', 13.8389, 'skinni men blue jean'), ('JEAFUZXTBXFBREYS', 13.5789, 'skinni men blue jean'), ('JEAFXUHCWV9C5WNX', 13.5789, 'super skinni men blue jean')]\n",
      "Q3 CUSTOM top-10: [('JEAFWBJKAY9UHW8T', 16.8565, 'skinni women blue jean'), ('JEAFUZXTDFARUHFR', 16.3807, 'skinni men blue jean'), ('JEAEYNV6QZHJZFRH', 16.3655, 'skinni women green jean'), ('JEAFUZXTFZGGMYFB', 16.3163, 'skinni women blue jean'), ('JEAFUZXTHCYGZJFH', 16.2953, 'skinni men grey jean'), ('JEAFUZXSBBCAY7V6', 16.2883, 'skinni women grey jean'), ('JEAFUZXSYS6GHGYH', 16.2464, 'skinni women blue jean'), ('JEAFUZXS4AGG5HAQ', 16.2464, 'skinni women blue jean'), ('JEAFUZXTHR9UUXCG', 16.2464, 'skinni men blue jean'), ('JEAFXUHHTJNVG3PK', 16.1127, 'super skinni women blue jean')]\n",
      "Q4 TFIDF top-10: [('CTPFVPFV43SVFUWY', 1.0, 'nulit satin tie pin set red'), ('CTPFVPDDUYKBTAKH', 1.0, 'nulit satin tie pin set red'), ('CTPFVPDB593WABGP', 1.0, 'nulit satin tie pin set red'), ('CTPFVPGPW8DU3XJF', 1.0, 'nulit satin tie pin set red'), ('CTPFVZTBFX56AB3T', 1.0, 'nulit satin tie cufflink red'), ('TSHFGDEYFEY63WQA', 1.0, 'solid men polo neck red green black tshirt pack 3'), ('TSHFHBNTSG3UQWTV', 1.0, 'solid women polo neck dark blue red pink tshirt pack 3'), ('TSHFHHRKSYBQKPYF', 1.0, 'self design solid men polo neck red maroon pink tshirt pack 3'), ('TSHFGBY7MTBRY7GY', 1.0, 'solid women polo neck red green blue tshirt pack 3'), ('TSHFGBYHVCC5JFQU', 1.0, 'solid women polo neck light blue red blue tshirt pack 3')]\n",
      "Q4 BM25 top-10: [('SWTFVMSDDZRPXAPT', 7.3806, 'stripe round neck casual women revers red sweater'), ('KTAF5SD2XS8HWYCX', 5.53, 'men solid cotton blend straight kurta red'), ('KTAFD2UBNTQPBGAE', 5.4488, 'men embroid cotton blend straight kurta red'), ('KTAFD2UBNRWRAQJW', 5.4488, 'women embroid cotton blend straight kurta red'), ('KTAFD2UBSDPHPHXC', 5.4488, 'men embroid cotton blend straight kurta red'), ('SHOFGHWY36ZXNKMT', 5.0763, 'men red'), ('SHOFU4TFVFTAMNPD', 4.9411, 'parti wear women red'), ('CTPFVZTEMJWEJJJV', 3.9023, 'nulit satin tie cufflink red'), ('CTPFVZTBFX56AB3T', 3.4017, 'nulit satin tie cufflink red'), ('CTPFVZTBN4GRZKXH', 3.4017, 'nulit satin tie cufflink red')]\n",
      "Q4 CUSTOM top-10: [('KTAFD2UBNTQPBGAE', 7.5105, 'men embroid cotton blend straight kurta red'), ('KTAFD2UBNRWRAQJW', 7.5105, 'women embroid cotton blend straight kurta red'), ('KTAFD2UBSDPHPHXC', 7.5105, 'men embroid cotton blend straight kurta red'), ('SWTFVMSDDZRPXAPT', 7.4826, 'stripe round neck casual women revers red sweater'), ('KTAF5SD2XS8HWYCX', 7.1428, 'men solid cotton blend straight kurta red'), ('SHOFGHWY36ZXNKMT', 7.0001, 'men red'), ('SHOFU4TFVFTAMNPD', 6.4274, 'parti wear women red'), ('CTPFVZTEMJWEJJJV', 5.598, 'nulit satin tie cufflink red'), ('CTPFVZTBN4GRZKXH', 4.5924, 'nulit satin tie cufflink red'), ('CTPFVZTBFX56AB3T', 4.5646, 'nulit satin tie cufflink red')]\n",
      "Q5 TFIDF top-10: [('SHTFRSB3ZTK4GVEA', 1.0, 'women slim fit checker spread collar casual shirt'), ('JEAFVWFK6AFRNSFY', 1.0, 'skinni women dark blue jean'), ('SHTFSH5VRDYPSGGK', 1.0, 'women regular fit checker casual shirt'), ('JEAFMJHQHTYUAH7E', 1.0, 'taper fit women blue jean'), ('JEAFZZ996ZCSU2Z5', 1.0, 'slim women blue jean'), ('SHTFRTGXFZFH4PJE', 1.0, 'men regular fit checker casual shirt'), ('TSHFPHPHR5HFEVQT', 1.0, 'solid women henley neck black tshirt pack 3'), ('TSHFPHPHADJRNGSZ', 1.0, 'solid women henley neck dark blue green tshirt pack 3'), ('TSHFPHPHMFZHKSKH', 1.0, 'solid women henley neck dark blue red tshirt pack 3'), ('TSHFPHPHHDHVKJ9U', 1.0, 'solid men henley neck red tshirt pack 3')]\n",
      "Q5 BM25 top-10: [('JCKFWZBYQM2KQXCZ', 13.4896, 'full sleev solid women leather jacket'), ('JCKFWZBYEHTX3PFG', 13.4896, 'full sleev solid women leather jacket'), ('JCKFWZBYSXCEQDYD', 13.4896, 'full sleev solid men leather jacket'), ('JCKFWZBYVHJGQDGT', 13.4896, 'full sleev solid men leather jacket'), ('JCKFWZBYPVVGAHUR', 13.4896, 'full sleev solid women leather jacket'), ('JCKFWZBYHDRNMSZF', 13.4896, 'full sleev solid men leather jacket'), ('JCKFWZBYFHGWZ6RF', 13.4896, 'full sleev solid men leather jacket'), ('JCKFWZBYPATZVGPB', 13.4896, 'full sleev solid men leather jacket'), ('JCKFXY6FKFXW66DD', 12.3529, 'full sleev solid women leather jacket'), ('JCKFXY6FZMWUMTD4', 12.3529, 'full sleev solid men leather jacket')]\n",
      "Q5 CUSTOM top-10: [('JCKFWZBYQM2KQXCZ', 15.8746, 'full sleev solid women leather jacket'), ('JCKFWZBYEHTX3PFG', 15.8746, 'full sleev solid women leather jacket'), ('JCKFWZBYSXCEQDYD', 15.8746, 'full sleev solid men leather jacket'), ('JCKFWZBYVHJGQDGT', 15.8746, 'full sleev solid men leather jacket'), ('JCKFWZBYPVVGAHUR', 15.8746, 'full sleev solid women leather jacket'), ('JCKFWZBYHDRNMSZF', 15.8746, 'full sleev solid men leather jacket'), ('JCKFWZBYFHGWZ6RF', 15.8746, 'full sleev solid men leather jacket'), ('JCKFWZBYPATZVGPB', 15.8746, 'full sleev solid men leather jacket'), ('JCKFBFFZP9NHYH9Y', 15.2496, 'full sleev appliqu women leather jacket'), ('JCKFBFFP4GQJ3Y32', 14.82, 'full sleev color block appliqu women leather jacket')]\n"
     ]
    }
   ],
   "source": [
    "for qid, res in demo_results.items():\n",
    "    print(f\"{qid} TFIDF top-10:\", res['TFIDF'])\n",
    "    print(f\"{qid} BM25 top-10:\", res['BM25'])\n",
    "    print(f\"{qid} CUSTOM top-10:\", res['CUSTOM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3_w2v_md",
   "metadata": {},
   "source": [
    "## Word2Vec + cosine ranking\n",
    "We train a Word2Vec model on the corpus (description + title + brand tokens). A query or document is represented by averaging the vectors of its words. We then compute cosine similarity between the query vector and candidate document vectors.\n",
    "\n",
    "We return the top 20 documents for each of the 5 queries under AND semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3_w2v_train",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from gensim.models import Word2Vec\n",
    "except ImportError:\n",
    "    raise ImportError(\"error\")\n",
    "\n",
    "w2v_dim = 100\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=ALL_TEXT_DOCS,\n",
    "    vector_size=w2v_dim,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    sg=1,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3_w2v_helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_w2v(tokens, model):\n",
    "    vecs = [model.wv[t] for t in tokens if t in model.wv]\n",
    "    if not vecs:\n",
    "        return None\n",
    "    return np.mean(vecs, axis=0)\n",
    "\n",
    "def rank_w2v_cosine(query_tokens, candidate_indices, k=20):\n",
    "    q_vec = average_w2v(query_tokens, w2v_model)\n",
    "    if q_vec is None:\n",
    "        return []\n",
    "    scored = []\n",
    "    for idx in candidate_indices:\n",
    "        row = df.iloc[idx]\n",
    "        d_vec = average_w2v(doc_text_tokens(row), w2v_model)\n",
    "        if d_vec is None:\n",
    "            continue\n",
    "        score = cosine(q_vec, d_vec)\n",
    "        scored.append((row, score))\n",
    "    return sorted(scored, key=lambda x: x[1], reverse=True)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3_w2v_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_results = {}\n",
    "for qid, q_terms in test_queries.items():\n",
    "    q_tokens = preprocess_query(q_terms)\n",
    "    cand_idx = retrieve_conjunctive_candidates(q_tokens)\n",
    "    w2v_scored = rank_w2v_cosine(q_tokens, cand_idx, k=20)\n",
    "    w2v_results[qid] = [(row['pid'], round(float(score), 4), \" \".join(row['title']) if isinstance(row['title'], list) else str(row['title'])) for row, score in w2v_scored]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3_w2v_print",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 by Word2Vec + cosine (conjunctive):\n",
      "Q1: [('TSHFH8HGZQYERVKF', 0.8011, 'solid men polo neck red white blue tshirt pack 3'), ('TSHFUNN2PHXF7GUH', 0.7647, 'solid men round neck dark blue tshirt'), ('TSHEU7DTUYMHMGW6', 0.7595, 'stripe women polo neck blue tshirt'), ('TSHFZQZAZD8MYBGZ', 0.7558, 'graphic print men round neck beig dark blue tshirt pack 2'), ('TSHFNWZUHE6PTYUG', 0.7549, 'typographi women round neck blue tshirt'), ('TSHFUNN2GGPB4PEH', 0.754, 'print women round neck white blue tshirt'), ('TSHFZ9JSB5MB9AAG', 0.7525, 'solid men v neck dark blue tshirt'), ('TSHFZQ3HHXFYTQJG', 0.7525, 'graphic print men round neck pink dark blue tshirt pack 2'), ('TSHFZKM8HSCZDQER', 0.7513, 'graphic print men round neck black dark blue tshirt pack 2'), ('TSHFUNN3ZJEKSAEV', 0.7512, 'print men round neck dark blue tshirt'), ('TSHFZPENQKGHKYTU', 0.7506, 'graphic print men round neck dark blue red tshirt pack 2'), ('TSHFZQZAE9C5UTTD', 0.7496, 'graphic print men round neck white dark blue tshirt pack 2'), ('TSHFZ9K3AX2MBCPM', 0.7466, 'solid men round neck blue tshirt'), ('TSHFYPGNHMKRUWAH', 0.7459, 'print men round neck dark blue tshirt'), ('TSHFZ6DBE7GBBF2T', 0.7371, 'graphic print women round neck light blue tshirt'), ('TSHFYWFQMUCGYVUV', 0.7286, 'graphic print women round neck dark blue tshirt'), ('TSHFYWFQCPZUSTGX', 0.7286, 'graphic print women round neck dark blue tshirt'), ('TSHFPWKTUZVPHHNQ', 0.7039, 'print women round neck red tshirt'), ('TSHFZDP8MWWFXZFC', 0.6863, 'graphic print men round neck white tshirt'), ('SWTFWG9RD4M6RSRZ', 0.6852, 'graphic print round neck casual men blue sweater')]\n",
      "Q2: [('TSHFZF6KAAJ3QBBZ', 0.7868, 'print women round neck red tshirt'), ('TSHFZF6KF2GKH5ZM', 0.7205, 'solid women round neck red tshirt')]\n",
      "Q3: [('JEAFZAUDSQBXBYWH', 0.8639, 'skinni men blue jean'), ('JEAFYA54APGZJ3CS', 0.8621, 'skinni women black jean'), ('JEAFNR7HYGPHGJEG', 0.8569, 'skinni men grey jean'), ('JEAFZJGGWHT8SDDN', 0.8533, 'skinni women grey jean'), ('JEAFG8BFHTD6SAQF', 0.8113, 'skinni women light blue jean'), ('JEAFG8BFYWZ8JSSP', 0.8102, 'skinni women dark blue jean'), ('JEAFUZ87WN7FWM8A', 0.8049, 'skinni women white jean'), ('JEAFWBJKAY9UHW8T', 0.7564, 'skinni women blue jean'), ('JEAFUZXTHR9UUXCG', 0.7531, 'skinni men blue jean'), ('JEAFUZXTDFARUHFR', 0.7509, 'skinni men blue jean'), ('JEAFUZXSYS6GHGYH', 0.7508, 'skinni women blue jean'), ('JEAFUZXTFZGGMYFB', 0.7508, 'skinni women blue jean'), ('JEAFUZXS4AGG5HAQ', 0.7508, 'skinni women blue jean'), ('JEAFUZXTHCYGZJFH', 0.7456, 'skinni men grey jean'), ('JEAFUZXSBBCAY7V6', 0.7452, 'skinni women grey jean'), ('JEAFXUHCWV9C5WNX', 0.744, 'super skinni men blue jean'), ('JEAFXUHFWQTBJTNG', 0.7411, 'super skinni men blue jean'), ('JEAFXUHTQGBVANVY', 0.7411, 'super skinni men blue jean'), ('JEAFXUHHTJNVG3PK', 0.7411, 'super skinni women blue jean'), ('JEAFUZXTBXFBREYS', 0.7386, 'skinni men blue jean')]\n",
      "Q4: [('SWTFVMSDDZRPXAPT', 0.6022, 'stripe round neck casual women revers red sweater'), ('KTAFD2UBNRWRAQJW', 0.544, 'women embroid cotton blend straight kurta red'), ('KTAFD2UBNTQPBGAE', 0.5438, 'men embroid cotton blend straight kurta red'), ('KTAFD2UBSDPHPHXC', 0.5438, 'men embroid cotton blend straight kurta red'), ('KTAF5SD2XS8HWYCX', 0.5409, 'men solid cotton blend straight kurta red'), ('SHTEMD8QKYNHW6HG', 0.5352, 'men regular fit solid regular collar formal shirt'), ('TSHFUWQAAECQFGJB', 0.5242, 'solid women v neck maroon tshirt'), ('TSHFUXPWUR2ZTEE2', 0.5227, 'color block men v neck dark blue tshirt'), ('SHOFGHWY36ZXNKMT', 0.5124, 'men red'), ('SHOFU4TFVFTAMNPD', 0.5123, 'parti wear women red'), ('ETHF2557X6HKRUY3', 0.5046, 'women ethnic jacket kurta set cotton jute blend'), ('ETHF2557HFUJKF6S', 0.5043, 'men ethnic jacket kurta set cotton jute blend'), ('ETHF2557NWFC5AS6', 0.5043, 'men ethnic jacket kurta set cotton jute blend'), ('TSHF4PFQK67YGUY7', 0.4988, 'solid men round neck white tshirt'), ('TSHFSA79BXZUERYB', 0.4975, 'print men round neck yellow tshirt'), ('TSHFSA79NFYWPMWT', 0.4975, 'print men round neck yellow tshirt'), ('TSHFGDEYAGYNKSF8', 0.4947, 'solid women polo neck light blue green yellow tshirt pack 3'), ('CTPFVZTEMJWEJJJV', 0.4939, 'nulit satin tie cufflink red'), ('TSHFGDDYKKGHGJUY', 0.4933, 'solid women polo neck green light green yellow tshirt pack 3'), ('TSHFHHRHH8THU3VZ', 0.4808, 'solid women polo neck dark blue pink orang tshirt pack 3')]\n",
      "Q5: [('JCKFWZBYQM2KQXCZ', 0.8035, 'full sleev solid women leather jacket'), ('JCKFWZBYEHTX3PFG', 0.8035, 'full sleev solid women leather jacket'), ('JCKFWZBYPVVGAHUR', 0.8035, 'full sleev solid women leather jacket'), ('JCKFWZBYSXCEQDYD', 0.8031, 'full sleev solid men leather jacket'), ('JCKFWZBYVHJGQDGT', 0.8031, 'full sleev solid men leather jacket'), ('JCKFWZBYHDRNMSZF', 0.8031, 'full sleev solid men leather jacket'), ('JCKFWZBYFHGWZ6RF', 0.8031, 'full sleev solid men leather jacket'), ('JCKFWZBYPATZVGPB', 0.8031, 'full sleev solid men leather jacket'), ('JCKF7FHYECSZGCQA', 0.7375, 'full sleev solid men quilt jacket'), ('JCKFBFFZP9NHYH9Y', 0.7337, 'full sleev appliqu women leather jacket'), ('JCKFXY6FKFXW66DD', 0.7318, 'full sleev solid women leather jacket'), ('JCKFXY6F9UFABRGP', 0.7318, 'full sleev solid women leather jacket'), ('JCKFXY6FHKFVSJEZ', 0.7318, 'full sleev solid women leather jacket'), ('JCKFXY6FPFZTG5WN', 0.7318, 'full sleev solid women leather jacket'), ('JCKFXY6FPHVHGFG4', 0.7318, 'full sleev solid women leather jacket'), ('JCKFAYVDMYZEAMUY', 0.7315, 'full sleev appliqu women leather jacket'), ('JCKFXY6FZMWUMTD4', 0.731, 'full sleev solid men leather jacket'), ('JCKFXY6FC8Z6YENR', 0.731, 'full sleev solid men leather jacket'), ('JCKFXY6FKF36GMNN', 0.731, 'full sleev solid men leather jacket'), ('JCKFBFFP26ZRP8WN', 0.7198, 'full sleev color block appliqu women leather jacket')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 20 by Word2Vec + cosine (conjunctive):\")\n",
    "for qid in [\"Q1\",\"Q2\",\"Q3\",\"Q4\",\"Q5\"]:\n",
    "    print(f\"{qid}:\", w2v_results.get(qid, []))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3_better_repr_md",
   "metadata": {},
   "source": [
    "## Beyond Word2Vec: better text representations?\n",
    "\n",
    "- Doc2Vec: learns document embeddings directly instead of averaging word vectors.\n",
    "  - Pros: captures document‑level semantics and word order context better than plain averaging.\n",
    "  - Cons: requires training on a large in‑domain corpus; quality depends on hyperparameters and data size.\n",
    "\n",
    "- Sentence embeddings (e.g., Sentence‑BERT): transformer models that produce semantically meaningful sentence/document vectors.\n",
    "  - Pros: strong performance on semantic similarity out of the box; captures context and polysemy.\n",
    "  - Cons: heavier to run; may require domain adaptation for best results; vectors are dense and larger.\n",
    "\n",
    "- Weighted Word2Vec (IDF‑weighted averaging): cheap improvement over uniform averaging by giving more weight to rarer, more informative terms.\n",
    "  - Pros: simple, fast, often better than plain average; easy to integrate with our existing IDF.\n",
    "  - Cons: still bag‑of‑words; limited ability to capture word order or complex context.\n",
    "\n",
    "Given our dataset size and the need for efficient retrieval, a strong next step would be to use IDF‑weighted Word2Vec or a lightweight sentence embedding model to improve semantic matching while keeping latency acceptable. For high accuracy scenarios (and if compute allows), Sentence‑BERT or similar models generally outperform Word2Vec."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
